{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"BioV","text":"<p>Next-generation development experience for computational molecular biology.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>LLM friendly/native/driven: Designed for seamless integration with large language models, built for LLM workflows, and optimized for LLM-assisted development</li> <li>Pydantic-powered: Built-in validation and serialization for robust data handling</li> <li>Pandas ecosystem: Developer-friendly DataFrame operations with extended bioinformatics capabilities</li> <li>Modern tooling: Full type hints support and configuration through environment variables</li> </ul>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>BioV can be configured through:</p> <ol> <li>Environment variables</li> <li><code>.env</code> files</li> <li>Runtime settings</li> </ol>"},{"location":"guides/configuration/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>BIOV_HOME</code> Platform cache dir Custom cache directory <code>BIOV_CACHE_HTTP</code> <code>True</code> Enable HTTP caching <pre><code>from biov.config import settings\nprint(settings.cache_http)\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>biov<ul> <li>config</li> <li>dataframe</li> <li>executables</li> <li>io<ul> <li>fastx</li> <li>gff</li> </ul> </li> <li>seq</li> </ul> </li> </ul>"},{"location":"reference/biov/","title":"Index","text":"<p>Next-generation development experience for computational molecular biology.</p>"},{"location":"reference/biov/config/","title":"config","text":"<p>Configuration module for BioV.</p>"},{"location":"reference/biov/config/#biov.config.Settings","title":"<code>Settings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Settings.</p> <p>Attributes:</p> Name Type Description <code>home</code> <code>Path</code> <p>Custom cache directory</p> <code>cache_http</code> <code>bool</code> <p>Cache file from http or not</p> Source code in <code>src/biov/config.py</code> <pre><code>class Settings(BaseSettings, env_prefix=\"BIOV_\"):\n    \"\"\"Settings.\n\n    Attributes:\n        home: Custom cache directory\n        cache_http: Cache file from http or not\n    \"\"\"\n\n    home: Path = Field(default_factory=get_default_home)\n    cache_http: bool = True\n</code></pre>"},{"location":"reference/biov/config/#biov.config.get_default_home","title":"<code>get_default_home()</code>","text":"<p>Get default BIOV_HOME.</p> <p>Returns:</p> Type Description <code>Path</code> <p>$XDG_CACHE_HOME/biov if XDG_CACHE_HOME set else determined by platformdirs</p> Source code in <code>src/biov/config.py</code> <pre><code>def get_default_home() -&gt; Path:\n    \"\"\"Get default BIOV_HOME.\n\n    Returns:\n        $XDG_CACHE_HOME/biov if XDG_CACHE_HOME set else determined by platformdirs\n    \"\"\"\n    if (xdg_cache_home := os.getenv(\"XDG_CACHE_HOME\")) is not None:\n        return Path(os.path.join(xdg_cache_home, appname))\n    else:\n        from platformdirs import PlatformDirs\n\n        return PlatformDirs(appname=appname).user_cache_path\n</code></pre>"},{"location":"reference/biov/dataframe/","title":"dataframe","text":"<p>DataFrame for biological data.</p>"},{"location":"reference/biov/dataframe/#biov.dataframe.BioDataFrame","title":"<code>BioDataFrame</code>","text":"<p>               Bases: <code>GFFMixin</code>, <code>DataFrame</code></p> <p>DataFrame for biological data.</p> <p>Attributes:</p> Name Type Description <code>_gff_columns</code> <code>list[str]</code> <p>Column names for GFF format. Length MUST be equal to 9.</p> Source code in <code>src/biov/dataframe.py</code> <pre><code>class BioDataFrame(GFFMixin, DataFrame):\n    \"\"\"DataFrame for biological data.\n\n    Attributes:\n        _gff_columns: Column names for GFF format. Length MUST be equal to 9.\n    \"\"\"\n\n    @property\n    def _constructor(self) -&gt; Callable[..., BioDataFrame]:\n        return BioDataFrame\n</code></pre>"},{"location":"reference/biov/seq/","title":"seq","text":"<p>Types for BioV.</p>"},{"location":"reference/biov/seq/#biov.seq.Seq","title":"<code>Seq</code>","text":"<p>               Bases: <code>Seq</code></p> <p>Extended from Bio.Seq.Seq for pydantic validation and serialization.</p> Source code in <code>src/biov/seq.py</code> <pre><code>class Seq(_Seq):\n    \"\"\"Extended from Bio.Seq.Seq for pydantic validation and serialization.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        \"\"\"Validation and serialization for Seq.\n\n        Returns:\n            validation and serialization schema\n        \"\"\"\n        return core_schema.no_info_plain_validator_function(\n            _Seq,\n            serialization=core_schema.to_string_ser_schema(),\n        )\n</code></pre>"},{"location":"reference/biov/seq/#biov.seq.Seq.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type, handler)</code>  <code>classmethod</code>","text":"<p>Validation and serialization for Seq.</p> <p>Returns:</p> Type Description <code>CoreSchema</code> <p>validation and serialization schema</p> Source code in <code>src/biov/seq.py</code> <pre><code>@classmethod\ndef __get_pydantic_core_schema__(\n    cls, source_type: Any, handler: GetCoreSchemaHandler\n) -&gt; CoreSchema:\n    \"\"\"Validation and serialization for Seq.\n\n    Returns:\n        validation and serialization schema\n    \"\"\"\n    return core_schema.no_info_plain_validator_function(\n        _Seq,\n        serialization=core_schema.to_string_ser_schema(),\n    )\n</code></pre>"},{"location":"reference/biov/executables/","title":"executables","text":"<p>Executables from various origin.</p>"},{"location":"reference/biov/executables/#biov.executables.blat","title":"<code>blat(database, query, **kwargs)</code>","text":"<p>Standalone BLAT v. 39x1 fast sequence search command line tool.</p> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str</code> <p>a .fa, .nib or .2bit file, or a list of these files with one file name per line.</p> required <code>query</code> <code>str | list[str]</code> <p>Same as database but additionally support directly providing sequence.</p> required <code>**kwargs</code> <code>Any</code> <p>extra options will pass directly to original blat executable.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame object</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if could not found blat in $BIOV_HOME/.bin:$PATH and could not rsync from ucsc.</p> <code>RuntimeError</code> <p>if error occurred while rsync.</p> Source code in <code>src/biov/executables/_blat.py</code> <pre><code>@typechecked\ndef blat(\n    database: str,\n    query: str | list[str],\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Standalone BLAT v. 39x1 fast sequence search command line tool.\n\n    Args:\n        database: a .fa, .nib or .2bit file, or a list of these files with one file name per line.\n        query: Same as database but additionally support directly providing sequence.\n        **kwargs: extra options will pass directly to original blat executable.\n\n    Returns:\n        a DataFrame object\n\n    Raises:\n        FileNotFoundError: if could not found blat in $BIOV_HOME/.bin:$PATH and could not rsync from ucsc.\n        RuntimeError: if error occurred while rsync.\n    \"\"\"\n    if isinstance(query, str):\n        query = [query]\n    bin_dir = settings.home / \".bin\"\n    bin_dir.mkdir(exist_ok=True, parents=True)\n    blat_exec = shutil.which(\"blat\", path=bin_dir)\n    if blat_exec is None:\n        blat_exec = shutil.which(\"blat\")\n    if blat_exec is None and _RSYNC_SUPPORTED:\n        rsync = shutil.which(\"rsync\")\n        if rsync is None:\n            raise FileNotFoundError(\"Sorry, biov could not find blat.\")\n        bin_dir = settings.home / \".bin\"\n        bin_dir.mkdir(exist_ok=True, parents=True)\n\n        try:\n            # ruff: noqa: S603\n            subprocess.run(\n                [\n                    rsync,\n                    \"-aP\",\n                    f\"rsync://hgdownload.soe.ucsc.edu/genome/admin/exe/{_SUBDIR}/blat/blat\",\n                    bin_dir,\n                ],\n                check=True,\n            )\n        except subprocess.CalledProcessError as e:\n            raise RuntimeError(\"Sorry, biov could not rsync blat from ucsc.\") from e\n        return blat(database, query, **kwargs)\n\n    if blat_exec is None:\n        raise FileNotFoundError(\"Sorry, biov could not find blat.\")\n\n    with ExitStack() as stack:\n        database = _handle_fsspec_path(database, stack)\n        queries = []\n        for _q in query:\n            _q = _handle_fsspec_path(_q, stack)\n            _q = _handle_seq(_q, stack)\n            queries.append(_q)\n        if len(queries) &gt; 1:\n            names_file = stack.enter_context(NamedTemporaryFile(\"w+t\"))\n            names_file.writelines([f\"{_q}\\n\" for _q in queries])\n            query = [names_file.name]\n        else:\n            query = queries\n        f = stack.enter_context(NamedTemporaryFile(mode=\"w+t\"))\n        subprocess.run(\n            [\n                blat_exec,\n                \"-noHead\",\n                *[\n                    f\"-{k}\" if isinstance(v, bool) and v else f\"-{k}={v}\"\n                    for k, v in kwargs.items()\n                    if v is not None\n                    if k != \"noHead\"\n                ],\n                database,\n                *query,\n                f.name,\n            ]\n        )\n        return pd.read_table(\n            f,\n            names=_BLAT_COLUMNS,\n        )\n</code></pre>"},{"location":"reference/biov/io/","title":"Index","text":"<p>Input/Output.</p>"},{"location":"reference/biov/io/fastx/","title":"fastx","text":"<p>Read FASTA and FASTQ file.</p>"},{"location":"reference/biov/io/fastx/#biov.io.fastx.read_fasta","title":"<code>read_fasta(filepath_or_buffer)</code>","text":"<p>Read FASTA sequence.</p> <p>Returns:</p> Type Description <code>dict[str, SeqRecord]</code> <p>a dict key as sequence id and value as SeqRecord.</p> Source code in <code>src/biov/io/fastx.py</code> <pre><code>def read_fasta(\n    filepath_or_buffer: FilePath | ReadBuffer,\n) -&gt; dict[str, SeqRecord]:\n    \"\"\"Read FASTA sequence.\n\n    Returns:\n        a dict key as sequence id and value as SeqRecord.\n    \"\"\"\n    filepath_or_buffer, _ = preprocessing(filepath_or_buffer)\n    if isinstance(filepath_or_buffer, str):\n        with fsspec.open(filepath_or_buffer, \"rt\", compression=\"infer\") as b:\n            return SeqIO.to_dict(SeqIO.parse(b, \"fasta\"))\n    else:\n        return SeqIO.to_dict(SeqIO.parse(filepath_or_buffer, \"fasta\"))\n</code></pre>"},{"location":"reference/biov/io/gff/","title":"gff","text":"<p>Generic Feature Format Version 3.</p> Specification <p>https://github.com/the-sequence-ontology/specifications/blob/master/gff3.md</p>"},{"location":"reference/biov/io/gff/#biov.io.gff.GFFMixin","title":"<code>GFFMixin</code>","text":"<p>Mixin class providing GFF3 format support for BioDataFrame.</p> <p>This mixin adds GFF3-specific functionality including: - Standard GFF3 column definitions - Methods for converting to GFF3 format</p> <p>Attributes:</p> Name Type Description <code>_gff_columns</code> <code>list[str]</code> <p>List of column names for GFF3 format. Defaults to standard GFF3 columns.           Can be overridden by subclasses to support custom GFF3 variants.</p> <p>Methods:</p> Name Description <code>to_gff3</code> <p>Convert DataFrame to GFF3 format string or file</p> <code>to_gff</code> <p>Alias for to_gff3</p> Source code in <code>src/biov/io/gff.py</code> <pre><code>class GFFMixin:\n    \"\"\"Mixin class providing GFF3 format support for BioDataFrame.\n\n    This mixin adds GFF3-specific functionality including:\n    - Standard GFF3 column definitions\n    - Methods for converting to GFF3 format\n\n    Attributes:\n        _gff_columns: List of column names for GFF3 format. Defaults to standard GFF3 columns.\n                      Can be overridden by subclasses to support custom GFF3 variants.\n\n    Methods:\n        to_gff3: Convert DataFrame to GFF3 format string or file\n        to_gff: Alias for to_gff3\n    \"\"\"\n\n    _gff_columns: list[str] = GFF_COLUMNS\n\n    to_gff3 = to_gff3\n    to_gff = to_gff3\n</code></pre>"},{"location":"reference/biov/io/gff/#biov.io.gff.quote","title":"<code>quote(s)</code>","text":"<p>GFF-specific quote function.</p> <p>Returns:</p> Type Description <code>str</code> <p>Quoted string.</p> Source code in <code>src/biov/io/gff.py</code> <pre><code>def quote(s: str) -&gt; str:\n    \"\"\"GFF-specific quote function.\n\n    Returns:\n        Quoted string.\n    \"\"\"\n    return s.translate(\n        str.maketrans(\n            {  # type: ignore[arg-type]\n                \";\": \"%3B\",\n                \"=\": \"%3D\",\n                \"&amp;\": \"%26\",\n                \",\": \"%2C\",\n                chr(0x7F): \"%7F\",\n                **{chr(i): f\"%{i:x}\".upper() for i in range(0x1F)},\n            }\n        )\n    )\n</code></pre>"},{"location":"reference/biov/io/gff/#biov.io.gff.read_gff3","title":"<code>read_gff3(filepath_or_buffer, explode_attributes=True, **kwargs)</code>","text":"<p>Read GFF3 files.</p> <p>Parameters:</p> Name Type Description Default <code>filepath_or_buffer</code> <code>FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]</code> <p>support fsspec chain (available in pandas 3.0)</p> required <code>explode_attributes</code> <code>bool</code> <p>explode attributes into columns, notice that attributes with same name as primary columns (such as <code>score</code>) will be ignored.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>will pass to <code>pd.read_table</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BioDataFrame</code> <p>A BioDataFrame with at least 9 columns</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if unintended parameters provided.</p> <p>Examples:</p> <p>You can directly pass HTTP url.</p> <pre><code>&gt;&gt;&gt; read_gff3(\"https://rice.uga.edu/osa1r7_download/osa1_r7.asm.repeat_masked.gff3.gz\")\n</code></pre> <p>You can also pass fsspec chain</p> <pre><code>&gt;&gt;&gt; read_gff3(\"tar://IRGSP-1.0_representative/transcripts.gff::https://rapdb.dna.affrc.go.jp/download/archive/irgsp1/IRGSP-1.0_representative_2025-03-19.tar.gz\")\n</code></pre> Source code in <code>src/biov/io/gff.py</code> <pre><code>def read_gff3(\n    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n    explode_attributes: bool = True,\n    **kwargs: Any,\n) -&gt; \"BioDataFrame\":\n    \"\"\"Read GFF3 files.\n\n    Args:\n        filepath_or_buffer: support fsspec chain (available in pandas 3.0)\n        explode_attributes: explode attributes into columns, notice that attributes with same name as primary columns (such as `score`) will be ignored.\n        **kwargs: will pass to `pd.read_table`\n\n    Returns:\n        A BioDataFrame with at least 9 columns\n\n    Raises:\n        ValueError: if unintended parameters provided.\n\n    Examples:\n        You can directly pass HTTP url.\n\n        &gt;&gt;&gt; read_gff3(\"https://rice.uga.edu/osa1r7_download/osa1_r7.asm.repeat_masked.gff3.gz\")\n\n        You can also pass fsspec chain\n\n        &gt;&gt;&gt; read_gff3(\"tar://IRGSP-1.0_representative/transcripts.gff::https://rapdb.dna.affrc.go.jp/download/archive/irgsp1/IRGSP-1.0_representative_2025-03-19.tar.gz\")\n    \"\"\"\n    for param in (\"comment\", \"na_values\"):\n        if param in kwargs:\n            raise ValueError(f\"Parameter '{param}' is not allowed\")\n    kwargs[\"comment\"] = \"#\"\n    kwargs[\"na_values\"] = \".\"\n    if \"names\" not in kwargs:\n        kwargs[\"names\"] = GFF_COLUMNS\n    names: list[str] = list(kwargs[\"names\"])\n    filepath_or_buffer, kwargs = preprocessing(filepath_or_buffer, **kwargs)\n\n    def explode(attributes: pd.Series):\n        attr_df = pd.json_normalize(\n            attributes.apply(\n                lambda attrs: dict(\n                    [unquote(i) for i in kv.split(\"=\", maxsplit=1)]\n                    for kv in attrs.split(\";\")\n                )\n                if isinstance(attrs, str)\n                else {}\n            )  # type: ignore\n        )\n        return attr_df[[c for c in attr_df.columns if c not in names]]\n\n    raw_df: pd.DataFrame = pd.read_table(filepath_or_buffer, dtype={}, **kwargs)\n    raw_df[\"start\"] -= 1\n    if explode_attributes:\n        raw_df = pd.concat(\n            [raw_df[names[:-1]], explode(raw_df[names[-1]])],  # pyright: ignore\n            axis=1,\n        )\n    from ..dataframe import BioDataFrame\n\n    bdf = BioDataFrame(raw_df)\n    bdf._gff_columns = names\n    return bdf\n</code></pre>"},{"location":"reference/biov/io/gff/#biov.io.gff.to_gff3","title":"<code>to_gff3(self, path=None, *, attributes=True)</code>","text":"<p>Convert BioDataFrame to GFF3 format string or write to file.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>BioDataFrame</code> <p>The BioDataFrame to convert. Must have proper GFF columns defined.</p> required <code>path</code> <code>FilePath | WriteBuffer[bytes] | None</code> <p>File path or buffer to write to. If None, returns the GFF3 string.</p> <code>None</code> <code>attributes</code> <code>str | list[str] | Literal[True]</code> <p>Controls which columns are included in the GFF attributes field. - True: Include all non-GFF columns as attributes (default) - str: Include single column as attribute - list[str]: Include specified columns as attributes</p> <code>True</code> <p>Returns:</p> Type Description <code>str | None</code> <p>If path is not provided, returns the GFF3 formatted string, else returns None after writing to file/buffer.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the BioDataFrame is malformed for GFF3 export or required columns are missing.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = BioDataFrame(...)  # with proper GFF columns\n&gt;&gt;&gt; gff_str = df.to_gff3()  # returns GFF3 string\n&gt;&gt;&gt; df.to_gff3(\"output.gff\")  # writes to file\n&gt;&gt;&gt; df.to_gff3(attributes=[\"ID\", \"Name\"])  # only include ID and Name in attributes\n</code></pre> Source code in <code>src/biov/io/gff.py</code> <pre><code>def to_gff3(\n    self: \"BioDataFrame\",\n    path: FilePath | WriteBuffer[bytes] | None = None,\n    *,\n    attributes: str | list[str] | Literal[True] = True,\n) -&gt; str | None:\n    \"\"\"Convert BioDataFrame to GFF3 format string or write to file.\n\n    Args:\n        self: The BioDataFrame to convert. Must have proper GFF columns defined.\n        path: File path or buffer to write to. If None, returns the GFF3 string.\n        attributes: Controls which columns are included in the GFF attributes field.\n            - True: Include all non-GFF columns as attributes (default)\n            - str: Include single column as attribute\n            - list[str]: Include specified columns as attributes\n\n    Returns:\n        If path is not provided, returns the GFF3 formatted string, else returns None after writing to file/buffer.\n\n    Raises:\n        ValueError: If the BioDataFrame is malformed for GFF3 export or required columns are missing.\n\n    Examples:\n        &gt;&gt;&gt; df = BioDataFrame(...)  # with proper GFF columns\n        &gt;&gt;&gt; gff_str = df.to_gff3()  # returns GFF3 string\n        &gt;&gt;&gt; df.to_gff3(\"output.gff\")  # writes to file\n        &gt;&gt;&gt; df.to_gff3(attributes=[\"ID\", \"Name\"])  # only include ID and Name in attributes\n    \"\"\"\n    names = self._gff_columns\n    if len(names) != 9:\n        raise ValueError(\"Malformed BioDataFrame for export to GFF3.\")\n    if attributes is True:\n        attributes = [c for c in self.columns if c not in names]\n    elif isinstance(attributes, str):\n        attributes = [attributes]\n    gff_df = self.copy()\n    gff_df[names[3]] += 1\n    defaults = {\n        1: \"biov\",  # source\n        2: \"gene\",  # type\n        5: pd.NA,  # score\n        6: pd.NA,  # strand\n        7: pd.NA,  # phase\n    }\n    for c in range(8):  # except attributes\n        if (name := names[c]) not in self.columns:\n            if (default := defaults.get(c)) is not None:\n                gff_df[name] = default\n            else:\n                raise ValueError(f\"Column `{name}` is required for exporting to GFF.\")\n    gff_df = gff_df[names[:-1]]\n    if len(attributes) == 0:\n        gff_df[\"attributes\"] = pd.NA\n    else:\n        gff_df[\"attributes\"] = [\n            \";\".join(\n                f\"{quote(k)}={quote(str(v))}\"\n                for k, v in r.items()\n                if isinstance(k, str) and not pd.isna(v)\n            )\n            for r in self[attributes].to_dict(orient=\"records\")  # pyright: ignore\n        ]\n    gff_feature = gff_df.to_csv(sep=\"\\t\", na_rep=\".\", index=False, header=False)\n    content = f\"\"\"##gff-version 3\\n{gff_feature}\"\"\"\n    if path is None:\n        return content\n    if isinstance(path, str | os.PathLike):\n        Path(path).write_text(content)\n        return None\n    path.write(content.encode())\n    return None\n</code></pre>"}]}